{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "\n",
    "### Objectives\n",
    "\n",
    "1. Understand Backpropagation\n",
    "2. Write a neural network with one or more hidden layers\n",
    "3. Solve the XOR\n",
    "4. Understand how to build general classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all relevant code from the previous lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "W1 = np.random.randn(3, 2)\n",
    "B1 = np.random.randn(3)\n",
    "W2 = np.random.randn(1, 3)\n",
    "B2 = np.random.randn(1)\n",
    "\n",
    "def sigm(X, W, B):\n",
    "    M = 1/(1+np.exp(-(X.dot(W.T)+B)))\n",
    "    return M\n",
    "\n",
    "def diff_W(X, Z, Y, B, W):\n",
    "\n",
    "    dS = sigm(X, W, B)*(1-sigm(X, W, B)) # differentiating sigm function\n",
    "    dW = (Y-Z)*dS\n",
    "\n",
    "    return X.T.dot(dW) # dot product between X transpose and dW\n",
    "\n",
    "def diff_B(X, Z, Y, B, W):\n",
    "\n",
    "    dS = sigm(X, W, B)*(1-sigm(X, W, B))\n",
    "    dB = (Y-Z)*dS\n",
    "\n",
    "    return dB.sum(axis=0)\n",
    "\n",
    "X = np.random.randint(2, size=[15, 2])\n",
    "Y = np.array(X[:,0] | X[:,1] ).T\n",
    "\n",
    "X_Test = np.random.randint(2, size=[15, 2])\n",
    "Y_Test = np.array(X[:,0] | X[:,1] ).T\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(500):\n",
    "    output = sigm(X, W, B)\n",
    "\n",
    "    W = W + (learning_rate * diff_W(X, output, Y, B, W).T)\n",
    "    B = B + learning_rate * diff_B(X, output, Y, B, W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the initialized weights and biases have been modified. </br>\n",
    "**Why do we set the dimensions of the weights as (3, 2) and (1,3)?** </br>\n",
    "XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in a forward function to reflect the network topology that we want to replicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward(X, W1, B1, W2, B2):\n",
    "    #first layer\n",
    "\n",
    "    H = sigm(X, W1, B1)\n",
    "\n",
    "    #second layer\n",
    "\n",
    "    Y = sigm(H, W2, B2)\n",
    "\n",
    "    # We return both the final output and the output from the hidden layer\n",
    "\n",
    "    return Y, H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation of backpropogation functions \n",
    "\n",
    "// insert derivation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_B2(Z, Y):\n",
    "    dB = (Z-Y)*Y*(1-Y)\n",
    "    return dB.sum(axis=0)\n",
    "\n",
    "def diff_W2(H, Z, Y):\n",
    "    dW = (Z-Y)*Y*(1-Y)\n",
    "    return H.T.dot(dW)\n",
    "\n",
    "def diff_W1(X, H, Z, Y, W2):\n",
    "    dZ = (Z-Y).dot(W2)*Y*(1-Y)*H*(1-H)\n",
    "    return X.T.dot(dZ)\n",
    "\n",
    "def diff_B1(Z, Y, W2, H):\n",
    "    return ((Z-Y).dot(W2)*Y*(1-Y)*H*(1-H)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the previous lab, we are not making use of the sigmoid function inside the update rules. Instead, we feed them the outputs from the middle layer (H, in this example). The results are the same and which expression you use is simply a matter of readbility and compactness of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32184/2603990229.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mForward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mW2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdiff_W2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mB2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mB2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdiff_B2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdiff_W1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Z' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "for epoch in range(10000):\n",
    "    Y, H = Forward(X, W1, B1, W2, B2)\n",
    "\n",
    "    W2 = W2 + learning_rate * diff_W2(H, Z, Y).T\n",
    "    B2 = B2 + learning_rate * diff_B2(Z, Y)\n",
    "    W1 = W1 + learning_rate * diff_W1(X, H, Z, Y, W2).T\n",
    "    B1 = B1 + learning_rate * diff_B1(Z, Y, W2, H)\n",
    "    if not epoch % 50:\n",
    "        Accuracy = 1 -np.mean((Z-Y)**2)\n",
    "        print(\"Epoch: \", epoch, \" Accuracy: \", Accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8944ac20941febd3898b0b9a08c0e7cafc7c4835a26d6ed6b5e365f07f1b2728"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
